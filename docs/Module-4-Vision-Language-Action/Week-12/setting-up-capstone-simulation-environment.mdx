---
title: "Setting Up the Full Capstone Simulation Environment"
sidebar_position: 2
---

# Setting Up the Full Capstone Simulation Environment

## Learning Objectives

By the end of this chapter, you should be able to:
- Configure a comprehensive simulation environment for the capstone project
- Integrate multiple simulation platforms (Isaac Sim, Gazebo, Unity)
- Set up the humanoid robot model with all required sensors and actuators
- Configure the digital twin environment with realistic physics and rendering
- Establish proper networking and communication interfaces
- Validate the simulation environment before proceeding with development

## Introduction to the Capstone Simulation Architecture

The capstone simulation environment forms the foundation upon which the entire project will be built. This environment must provide a realistic, comprehensive, and extensible platform for developing and validating all aspects of the humanoid robot system. The simulation environment serves multiple purposes: it acts as a testing ground for complex algorithms, a development platform for debugging complex systems, and a validation environment for ensuring safe behavior before real-world deployment.

The capstone simulation environment is architecturally complex, integrating multiple simulation platforms to leverage their individual strengths. NVIDIA Isaac Sim provides state-of-the-art physics simulation and synthetic data generation capabilities. Gazebo offers robust ROS integration and well-established physics modeling. Unity provides photorealistic rendering and intuitive user interface development capabilities. The integration of these platforms creates a comprehensive digital twin environment that supports all aspects of humanoid robot development.

The simulation environment must be sufficiently realistic to enable the development of transferable skills while remaining efficient enough to support extensive testing and validation. Achieving this balance requires careful configuration of physics parameters, sensor models, and environmental conditions that match real-world characteristics as closely as possible.

## Environment Setup Prerequisites

### System Requirements

Before beginning the simulation environment setup, ensure your system meets the following requirements:

**Hardware Specifications**:
- **GPU**: NVIDIA RTX Series (RTX 3080/4080 or higher recommended) with CUDA support
- **VRAM**: 12GB+ VRAM for complex simulation scenarios
- **RAM**: 32GB+ system RAM (64GB recommended for large-scale simulation)
- **CPU**: Multi-core processor (Intel i9 or AMD Ryzen 9 with 8+ cores)
- **Storage**: Fast SSD with 500GB+ available space for simulation assets
- **Networking**: Gigabit Ethernet for multi-platform communication

**Software Prerequisites**:
- **Operating System**: Ubuntu 22.04 LTS or Windows 11 Pro
- **CUDA Toolkit**: Version 11.8 or higher with compatible drivers
- **Docker**: Latest version for containerized simulation environments
- **Git**: Latest version for version control and asset management
- **Python**: 3.10+ with pip for package management
- **NVIDIA Omniverse**: For Isaac Sim integration

### Development Environment Preparation

Setting up the foundational development environment:

**Workspace Organization**:
```bash
# Create project structure
mkdir -p ~/capstone_project/{isaac_sim,gazebo,unity,ros_packages,assets,docs,scripts}

# Set environment variables
echo 'export CAPSTONE_WS=~/capstone_project' >> ~/.bashrc
echo 'export ISAAC_SIM_PATH=$CAPSTONE_WS/isaac_sim' >> ~/.bashrc
echo 'export GAZEBO_WS=$CAPSTONE_WS/gazebo' >> ~/.bashrc
echo 'export UNITY_ASSETS=$CAPSTONE_WS/unity' >> ~/.bashrc
source ~/.bashrc
```

**ROS 2 Environment**:
```bash
# Install ROS 2 Humble Hawksbill
sudo apt update
sudo apt install ros-humble-desktop-full
echo 'source /opt/ros/humble/setup.bash' >> ~/.bashrc

# Install additional ROS packages
sudo apt install python3-colcon-common-extensions
sudo apt install python3-rosdep python3-vcstool
```

**Python Environment**:
```bash
# Set up Python virtual environment
python3 -m venv ~/capstone_env
source ~/capstone_env/bin/activate
pip install --upgrade pip setuptools

# Install required Python packages
pip install numpy matplotlib scipy
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install openai gymnasium
```

## Isaac Sim Configuration

### Isaac Sim Installation and Setup

Installing and configuring NVIDIA Isaac Sim for the capstone project:

**Download and Install Isaac Sim**:
```bash
# Download Isaac Sim from NVIDIA Developer Portal
# Follow installation instructions specific to your system
# Verify installation
cd /path/to/isaac_sim
python -c "import omni; print('Isaac Sim imported successfully')"
```

**Configure Isaac Sim Assets**:
```bash
# Set up asset directories
mkdir -p ~/capstone_project/isaac_sim/assets/{robots,environments,objects}
mkdir -p ~/capstone_project/isaac_sim/configs

# Download required assets from NVIDIA Omniverse
# Configure asset paths in Isaac Sim
```

**Launch Isaac Sim with Custom Configuration**:
```python
# capstone_isaac_launcher.py
import omni
from omni.isaac.kit import SimulationApp

# Configure simulation settings
config = {
    "experience": "omni.isaac.sim.python_app",
    "headless": False,  # Set to True for headless operation
    "window_width": 1920,
    "window_height": 1080,
    "gpu": True,
    "anti_aliasing": 8,
    "subdiv_rendering": True,
    "ssgi": True,
    "tiled_rendering": True,
    "tiled_rendering_tilesX": 2,
    "tiled_rendering_tilesY": 2,
    "rtx_direct": True,
    "nvflex": False,
    "max_gpu_cache_size": 1024,
    "max_cpu_cache_percent": 10,
    "l2_cache_size": 256
}

simulation_app = SimulationApp(config)

# Configure rendering and physics
from omni.isaac.core import World
from omni.isaac.core.utils.stage import add_reference_to_stage

world = World(stage_units_in_meters=1.0)

# Add your humanoid robot model
add_reference_to_stage(
    usd_path="/path/to/humanoid/model.usd",
    prim_path="/World/Humanoid"
)

# Configure physics settings
world.physics_context.set_gravity(9.81)
world.physics_context.set_physics_solver_type("TGS")  # Time Galerkin Solver
world.physics_context.set_friction_combine_mode("average")
world.physics_context.set_rest_combine_mode("average")

while simulation_app.is_running():
    world.step(render=True)
    # Add your robot control loop here

simulation_app.close()
```

### Humanoid Robot Model Setup

Configuring the humanoid robot model in Isaac Sim:

**Robot Model Configuration**:
```python
# humanoid_setup.py
from omni.isaac.core import World
from omni.isaac.core.robots import Robot
from omni.isaac.core.utils.nucleus import get_assets_root_path
from omni.isaac.core.utils.stage import add_reference_to_stage
from omni.isaac.core.articulations import ArticulationView
import numpy as np

class CapstoneHumanoid(Robot):
    def __init__(
        self,
        prim_path: str,
        name: str = "capstone_humanoid",
        usd_path: str = "/path/to/humanoid_model.usd",
        position: np.ndarray = np.array([0.0, 0.0, 0.0]),
        orientation: np.ndarray = np.array([1.0, 0.0, 0.0, 0.0])
    ):
        self._usd_path = usd_path
        self._position = position
        self._orientation = orientation
        self._name = name
        
        # Import the robot model
        add_reference_to_stage(
            usd_path=self._usd_path,
            prim_path=prim_path
        )
        
        super().__init__(
            prim_path=prim_path,
            name=name,
            position=position,
            orientation=orientation
        )
    
    def initialize(self, world: World):
        super().initialize(world=world)
        self._articulation_controller = self.get_articulation_controller()
        
        # Initialize sensors (IMU, cameras, etc.)
        self.setup_sensors()
        
        # Initialize controller parameters
        self.configure_joints()
    
    def setup_sensors(self):
        # Add IMU
        self.attach_imu_sensor(
            "body",  # Usually attached to torso
            frequency=100
        )
        
        # Add camera sensors
        self.setup_head_camera()
        self.setup_eye_cameras()  # Stereoscopic vision
        
        # Add force/torque sensors
        self.setup_foot_sensors()
        self.setup_hand_sensors()
    
    def configure_joints(self):
        # Configure joint limits, damping, stiffness
        joint_names = self.get_dof_names()
        joint_indices = self.get_dof_indices()
        
        for i, name in enumerate(joint_names):
            # Set appropriate limits based on humanoid model
            self.set_joint_position_limits(
                joint_indices[i],
                lower=-np.pi/2,  # Example limits
                upper=np.pi/2
            )
            
            # Set damping and stiffness
            self.set_drive_property(
                joint_indices[i],
                "damping",
                10.0,
                target_type="angular"
            )
            self.set_drive_property(
                joint_indices[i],
                "stiffness",
                1000.0,
                target_type="angular"
            )
    
    def get_robot_state(self):
        # Return comprehensive robot state
        joint_positions = self.get_joint_positions()
        joint_velocities = self.get_joint_velocities()
        root_pose = self.get_world_poses()
        imu_data = self.get_imu_data()
        
        return {
            "joint_positions": joint_positions,
            "joint_velocities": joint_velocities,
            "root_pose": root_pose,
            "imu_data": imu_data,
            "timestamp": self.get_world().current_time
        }
```

### Physics Configuration

Configuring realistic physics for the humanoid robot:

**Physics Parameters**:
```python
# physics_config.py
import omni
from omni.isaac.core import World
from pxr import PhysxSchema

def configure_physics_properties(world: World):
    """
    Configure physics properties for realistic humanoid simulation
    """
    physics_ctx = world.physics_context
    physics_ctx.set_gravity(9.81)
    
    # Solver settings
    physics_ctx.set_physics_solver_type("TGS")  # Time Galerkin Solver
    physics_ctx.set_solver_position_iteration_count(16)
    physics_ctx.set_solver_velocity_iteration_count(8)
    
    # Contact settings
    physics_ctx.set_enable_ccd(True)  # Continuous collision detection
    physics_ctx.enable_gpu_physics(True)
    
    # Ground plane setup
    setup_ground_plane(world)

def setup_ground_plane(world: World):
    """
    Configure ground plane with appropriate friction and restitution
    """
    from omni.isaac.core.objects.ground_plane import GroundPlane
    
    ground_plane = GroundPlane(
        prim_path="/World/GroundPlane",
        name="ground_plane",
        z_position=0,
        size=1000,
        color=np.array([0.2, 0.2, 0.2])
    )
    
    # Set ground properties
    world.scene.add_ground_plane(
        "ground_plane",
        collision_group="ground",
        friction=0.8,  # High friction for stability
        restitution=0.1  # Low bounce for realistic behavior
    )

def configure_material_properties(prim_path: str):
    """
    Configure material properties for robot links
    """
    stage = omni.usd.get_context().get_stage()
    prim = stage.GetPrimAtPath(prim_path)
    
    # Create material
    material_path = f"{prim_path}/material"
    material = PhysxSchema.PhysxMaterial.Define(stage, material_path)
    
    # Set material properties
    material.CreateStaticFrictionAttr(0.7)
    material.CreateDynamicFrictionAttr(0.5)
    material.CreateRestitutionAttr(0.2)
    
    # Apply material to collision
    collision_api = PhysxSchema.PhysxCollisionAPI(prim)
    collision_api.GetMaterialRel().SetTargets([material_path])
```

## Gazebo Integration

### Gazebo Configuration for Capstone

Setting up Gazebo as a complementary simulation platform:

**Gazebo Installation and Configuration**:
```bash
# Install Gazebo Garden
sudo apt install ros-humble-gazebo-*
sudo apt install gazebo libgazebo-dev

# Verify installation
gazebo --version

# Set up Gazebo environment
echo 'source /usr/share/gazebo/setup.sh' >> ~/.bashrc
```

**ROS-2 Gazebo Integration**:
```xml
<!-- capstone_robot_description/urdf/capstone_humanoid.urdf -->
<?xml version="1.0"?>
<robot name="capstone_humanoid" xmlns:xacro="http://www.ros.org/wiki/xacro">
  <!-- Base link -->
  <link name="base_link">
    <visual>
      <geometry>
        <cylinder radius="0.1" length="0.2"/>
      </geometry>
      <material name="blue">
        <color rgba="0 0 1 1"/>
      </material>
    </visual>
    <collision>
      <geometry>
        <cylinder radius="0.1" length="0.2"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="10.0"/>
      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.1"/>
    </inertial>
  </link>

  <!-- Torso -->
  <joint name="torso_joint" type="fixed">
    <parent link="base_link"/>
    <child link="torso"/>
    <origin xyz="0 0 0.2" rpy="0 0 0"/>
  </joint>

  <link name="torso">
    <visual>
      <geometry>
        <box size="0.5 0.3 0.8"/>
      </geometry>
      <material name="red">
        <color rgba="1 0 0 1"/>
      </material>
    </visual>
    <collision>
      <geometry>
        <box size="0.5 0.3 0.8"/>
      </geometry>
    </collision>
    <inertial>
      <mass value="20.0"/>
      <inertia ixx="0.5" ixy="0.0" ixz="0.0" iyy="0.5" iyz="0.0" izz="0.5"/>
    </inertial>
  </link>

  <!-- Additional links for legs, arms, and head would continue -->
  
  <!-- Gazebo plugins -->
  <gazebo>
    <plugin name="gazebo_ros_control" filename="libgazebo_ros_control.so">
      <robotNamespace>/capstone_humanoid</robotNamespace>
      <robotSimType>gazebo_ros_control/DefaultRobotHWSim</robotSimType>
    </plugin>
  </gazebo>

  <gazebo reference="base_link">
    <material>Gazebo/Black</material>
  </gazebo>

  <gazebo reference="torso">
    <material>Gazebo/Red</material>
  </gazebo>
</robot>
```

**Gazebo Controller Configuration**:
```yaml
# capstone_robot_control/config/joint_trajectory_controller.yaml
capstone_humanoid:
  controller_manager:
    ros__parameters:
      update_rate: 100  # Hz

      joint_trajectory_controller:
        type: joint_trajectory_controller/JointTrajectoryController

      # Other controllers...
  joint_trajectory_controller:
    ros__parameters:
      joints:
        - hip_joint_left
        - knee_joint_left
        - ankle_joint_left
        # ... continue for all joints

      command_interfaces:
        - position

      state_interfaces:
        - position
        - velocity

      state_publish_rate: 50.0
      action_monitor_rate: 20.0
      allow_partial_joints_goal: false
      constraints:
        stopped_velocity_tolerance: 0.01
        goal_time: 0.0
```

## Unity Integration Setup

### Unity Environment Configuration

Setting up Unity for visualization and user interaction components:

**Unity Project Setup**:
```bash
# Create Unity project
mkdir ~/capstone_project/unity/capstone_visualization
cd ~/capstone_project/unity/capstone_visualization

# Initialize as Unity project (this requires Unity Hub installed)
# From Unity Hub, create new 3D project named "capstone_visualization"
```

**ROS-TCP-Connector Integration**:
```csharp
// Assets/Scripts/CapstoneRosConnector.cs
using UnityEngine;
using Unity.Robotics.ROSTCPConnector;
using Unity.Robotics.ROSTCPConnector.MessageGeneration;

public class CapstoneRosConnector : MonoBehaviour
{
    [SerializeField] private string rosIpAddress = "127.0.0.1";
    [SerializeField] private int rosPort = 10000;
    
    private ROSConnection ros;
    
    // Robot state variables
    private Vector3 robotPosition;
    private Quaternion robotRotation;
    private float[] jointPositions;
    
    void Start()
    {
        ros = ROSConnection.instance;
        ros.Initialize(rosIpAddress, rosPort);
        
        // Start listening to robot state topics
        ros.Subscribe<sensor_msgs.msg.JointState>("/capstone_humanoid/joint_states", ReceiveJointStates);
        ros.Subscribe<geometry_msgs.msg.PoseStamped>("/capstone_humanoid/pose", ReceivePose);
        
        // Publisher for control commands
        InvokeRepeating("PublishControlCommands", 0.0f, 0.1f);
    }
    
    void ReceiveJointStates(sensor_msgs.msg.JointState jointState)
    {
        // Update robot joint positions in Unity
        jointPositions = jointState.position.ToArray();
        UpdateRobotModel();
    }
    
    void ReceivePose(geometry_msgs.msg.PoseStamped pose)
    {
        // Update robot pose in Unity
        robotPosition = new Vector3(
            (float)pose.pose.position.x,
            (float)pose.pose.position.z,  // Swap Y and Z to match Unity coordinates
            (float)pose.pose.position.y
        );
        
        robotRotation = new Quaternion(
            (float)pose.pose.orientation.x,
            (float)pose.pose.orientation.z,
            (float)pose.pose.orientation.y,
            (float)pose.pose.orientation.w
        );
        
        transform.position = robotPosition;
        transform.rotation = robotRotation;
    }
    
    void UpdateRobotModel()
    {
        // Update the 3D model's joint positions based on jointPositions array
        GameObject[] joints = GameObject.FindGameObjectsWithTag("RobotJoint");
        
        for (int i = 0; i < joints.Length && i < jointPositions.Length; i++)
        {
            // Rotate joint based on position
            joints[i].transform.localRotation = Quaternion.Euler(0, 0, jointPositions[i] * Mathf.Rad2Deg);
        }
    }
    
    void PublishControlCommands()
    {
        // Example: Publish velocity commands
        geometry_msgs.msg.Twist cmdVel = new geometry_msgs.msg.Twist();
        cmdVel.linear.x = 0.5f;  // Move forward
        cmdVel.angular.z = 0.1f; // Turn slightly
        
        ros.Publish("/capstone_humanoid/cmd_vel", cmdVel);
    }
    
    void OnDestroy()
    {
        if (ros != null)
        {
            ros.Close();
        }
    }
}
```

### Unity Visualization Components

Creating visualization components for the capstone project:

```csharp
// Assets/Scripts/CapstoneVisualization.cs
using UnityEngine;
using System.Collections.Generic;

public class CapstoneVisualization : MonoBehaviour
{
    [Header("Environment Visualization")]
    public Material groundMaterial;
    public Material obstacleMaterial;
    
    [Header("Robot Visualization")]
    public GameObject robotModel;
    public Material robotBodyMaterial;
    public Material robotJointMaterial;
    
    [Header("Sensor Visualization")]
    public GameObject lidarVisualization;
    public GameObject cameraFrustumVisualization;
    
    [Header("UI Components")]
    public GameObject statusPanel;
    public GameObject controlPanel;
    
    private Dictionary<string, GameObject> visualizationObjects = new Dictionary<string, GameObject>();
    
    void Start()
    {
        InitializeVisualization();
        SetupEnvironmentalRendering();
        ConfigureSensorVisualizations();
        InitializeUI();
    }
    
    void InitializeVisualization()
    {
        // Create ground plane
        CreateGroundPlane();
        
        // Setup lighting system
        SetupLighting();
        
        // Initialize robot visualization
        InitializeRobotVisualization();
    }
    
    void CreateGroundPlane()
    {
        GameObject ground = GameObject.CreatePrimitive(PrimitiveType.Plane);
        ground.name = "Environment_Ground";
        ground.transform.localScale = new Vector3(10, 1, 10);  // 10x10 meter area
        ground.GetComponent<Renderer>().material = groundMaterial;
        ground.transform.position = new Vector3(0, -0.01f, 0);  // Slightly below 0 for proper shadow casting
    }
    
    void SetupLighting()
    {
        // Remove default light and add custom lighting
        Light[] lights = FindObjectsOfType<Light>();
        foreach (Light light in lights)
        {
            DestroyImmediate(light.gameObject);
        }
        
        // Add directional light
        GameObject sun = new GameObject("Main_Light");
        Light sunLight = sun.AddComponent<Light>();
        sunLight.type = LightType.Directional;
        sunLight.color = Color.white;
        sunLight.intensity = 1.0f;
        sun.transform.rotation = Quaternion.Euler(45, 45, 0);
    }
    
    void InitializeRobotVisualization()
    {
        if (robotModel != null)
        {
            GameObject instantiatedRobot = Instantiate(robotModel);
            instantiatedRobot.name = "Capstone_Humanoid_Visualization";
            instantiatedRobot.transform.position = Vector3.zero;
            
            // Apply materials
            Renderer[] renderers = instantiatedRobot.GetComponentsInChildren<Renderer>();
            foreach (Renderer renderer in renderers)
            {
                if (renderer.name.Contains("Body") || renderer.name.Contains("Torso"))
                {
                    renderer.material = robotBodyMaterial;
                }
                else if (renderer.name.Contains("Joint") || renderer.name.Contains("Limb"))
                {
                    renderer.material = robotJointMaterial;
                }
            }
        }
    }
    
    void SetupEnvironmentalRendering()
    {
        // Create environment objects based on ROS map data
        // This would typically subscribe to /map topic
    }
    
    void ConfigureSensorVisualizations()
    {
        // Setup LiDAR visualization
        SetupLiDARVisualization();
        
        // Setup camera view frustum visualization
        SetupCameraVisualization();
    }
    
    void SetupLiDARVisualization()
    {
        if (lidarVisualization != null)
        {
            GameObject lidarVis = Instantiate(lidarVisualization);
            lidarVis.name = "LiDAR_Visualization";
            lidarVis.transform.SetParent(transform);
        }
    }
    
    void SetupCameraVisualization()
    {
        if (cameraFrustumVisualization != null)
        {
            GameObject camVis = Instantiate(cameraFrustumVisualization);
            camVis.name = "Camera_Visualization";
            camVis.transform.SetParent(transform);
        }
    }
    
    void InitializeUI()
    {
        if (statusPanel != null)
        {
            GameObject status = Instantiate(statusPanel);
            status.name = "Robot_Status_Panel";
            // Configure status panel to display robot health, battery, etc.
        }
        
        if (controlPanel != null)
        {
            GameObject ctrl = Instantiate(controlPanel);
            ctrl.name = "Robot_Control_Panel";
            // Configure control panel for manual robot control
        }
    }
    
    public void UpdateRobotStatus(Dictionary<string, object> statusData)
    {
        // Update visualization based on robot status data
        // This could update battery level, joint temperatures, etc.
    }
}
```

## Networking and Communication Setup

### ROS 2 Communication Architecture

Setting up the communication infrastructure between simulation components:

**Launch File Configuration**:
```python
# capstone_project/launch/capstone_simulation.launch.py
import os
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument, IncludeLaunchDescription
from launch.launch_description_sources import PythonLaunchDescriptionSource
from launch.substitutions import LaunchConfiguration, PathJoinSubstitution
from launch_ros.actions import Node, ComposableNodeContainer
from launch_ros.descriptions import ComposableNode
from ament_index_python.packages import get_package_share_directory

def generate_launch_description():
    # Declare launch arguments
    use_sim_time = LaunchConfiguration('use_sim_time')
    launch_prefix = LaunchConfiguration('launch_prefix', default='')
    
    # Simulation time configuration
    declare_use_sim_time = DeclareLaunchArgument(
        'use_sim_time',
        default_value='true',
        description='Use simulation (Gazebo) clock if true'
    )
    
    # Robot state publisher
    robot_description_path = PathJoinSubstitution([
        get_package_share_directory('capstone_robot_description'),
        'urdf',
        'capstone_humanoid.urdf'
    ])
    
    robot_state_publisher = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        name='robot_state_publisher',
        output='both',
        parameters=[
            {'use_sim_time': use_sim_time},
            {'robot_description': PathJoinSubstitution([
                get_package_share_directory('capstone_robot_description'),
                'urdf',
                'capstone_humanoid.urdf'
            ])}
        ]
    )
    
    # Joint state publisher
    joint_state_publisher = Node(
        package='joint_state_publisher',
        executable='joint_state_publisher',
        name='joint_state_publisher',
        output='both',
        parameters=[{'use_sim_time': use_sim_time}]
    )
    
    # Controllers
    controller_manager = Node(
        package='controller_manager',
        executable='ros2_control_node',
        parameters=[
            PathJoinSubstitution([
                get_package_share_directory('capstone_robot_control'),
                'config',
                'joint_trajectory_controller.yaml'
            ]),
            {'use_sim_time': use_sim_time}
        ],
        output='both'
    )
    
    # Perception pipeline
    perception_pipeline = ComposableNodeContainer(
        name='perception_container',
        namespace='',
        package='rclcpp_components',
        executable='component_container_mt',
        composable_node_descriptions=[
            ComposableNode(
                package='capstone_perception',
                plugin='capstone_perception::PointCloudProcessor',
                name='pointcloud_processor',
                parameters=[{'use_sim_time': use_sim_time}]
            ),
            ComposableNode(
                package='capstone_perception',
                plugin='capstone_perception::ImageProcessor',
                name='image_processor',
                parameters=[{'use_sim_time': use_sim_time}]
            )
        ],
        output='both'
    )
    
    # Navigation stack
    navigation_stack = IncludeLaunchDescription(
        PythonLaunchDescriptionSource([
            PathJoinSubstitution([
                get_package_share_directory('nav2_bringup'),
                'launch',
                'navigation_launch.py'
            ])
        ]),
        launch_arguments={
            'use_sim_time': use_sim_time,
            'params_file': PathJoinSubstitution([
                get_package_share_directory('capstone_bringup'),
                'config',
                'nav2_params.yaml'
            ])
        }.items()
    )
    
    # Isaac Sim bridge (if using external Isaac Sim)
    isaac_bridge = Node(
        package='isaac_ros_messages',
        executable='isaac_bridge',
        name='isaac_bridge',
        parameters=[
            {'use_sim_time': use_sim_time}
        ],
        output='both'
    )
    
    return LaunchDescription([
        declare_use_sim_time,
        robot_state_publisher,
        joint_state_publisher,
        controller_manager,
        perception_pipeline,
        navigation_stack,
        isaac_bridge
    ])
```

### Communication Interface Configuration

Configuring the interfaces between different simulation components:

**Parameter Configuration**:
```yaml
# capstone_project/config/capstone_params.yaml
capstone_humanoid:
  ros__parameters:
    # General robot parameters
    robot_name: "capstone_humanoid"
    use_sim_time: true
    publish_frequency: 50.0
    
    # Locomotion parameters
    locomotion:
      max_vel_x: 0.5
      max_vel_y: 0.2
      max_vel_theta: 0.5
      acc_lim_x: 0.5
      acc_lim_y: 0.2
      acc_lim_theta: 0.5
      decel_lim_x: -0.5
      decel_lim_y: -0.2
      decel_lim_theta: -0.5
    
    # Perception parameters
    perception:
      camera_hz: 30.0
      lidar_hz: 10.0
      imu_hz: 100.0
      
      # Processing parameters
      detection_range_min: 0.1
      detection_range_max: 10.0
      fov_horizontal: 1.047  # 60 degrees in radians
      fov_vertical: 0.785   # 45 degrees in radians
      
    # Safety parameters
    safety:
      safe_distance: 0.5
      emergency_stop_distance: 0.2
      max_joint_velocity: 1.5
      max_joint_effort: 100.0
    
    # Behavior parameters
    behaviors:
      default_behavior_speed: 0.8
      attention_span: 10.0  # seconds before switching to idle
      interaction_timeout: 30.0  # seconds for interaction timeout
```

## Validation and Testing

### Environment Validation

Validating that the simulation environment is properly configured:

**Validation Scripts**:
```python
# validation/environment_validator.py
import unittest
import rospy
from std_msgs.msg import Bool
from sensor_msgs.msg import JointState
from geometry_msgs.msg import Pose
import time

class EnvironmentValidator(unittest.TestCase):
    def setUp(self):
        rospy.init_node('environment_validator', anonymous=True)
        self.timeout = 10.0  # seconds
        
        # Subscribers for validation
        self.joint_state_received = False
        self.pose_received = False
        self.health_status = None
        
        self.joint_sub = rospy.Subscriber('/capstone_humanoid/joint_states', JointState, self.joint_state_callback)
        self.pose_sub = rospy.Subscriber('/capstone_humanoid/pose', Pose, self.pose_callback)
        self.health_sub = rospy.Subscriber('/capstone_humanoid/health_status', Bool, self.health_callback)
    
    def joint_state_callback(self, msg):
        if len(msg.position) > 0:
            self.joint_state_received = True
    
    def pose_callback(self, msg):
        self.pose_received = True
    
    def health_callback(self, msg):
        self.health_status = msg.data
    
    def test_robot_spawn(self):
        """Test that the robot model spawns correctly in simulation"""
        timeout = time.time() + self.timeout
        while not (self.joint_state_received and self.pose_received):
            if time.time() > timeout:
                self.fail("Robot model did not spawn correctly - no joint states or pose received")
            time.sleep(0.1)
        
        self.assertTrue(self.joint_state_received, "Joint states not received")
        self.assertTrue(self.pose_received, "Pose not received")
    
    def test_sensor_data_flow(self):
        """Test sensor data is flowing correctly"""
        timeout = time.time() + self.timeout
        while not self.joint_state_received:
            if time.time() > timeout:
                self.fail("Sensor data not flowing correctly")
            time.sleep(0.1)
        
        # Check that joint state has reasonable number of joints
        js_msg = rospy.wait_for_message('/capstone_humanoid/joint_states', JointState, timeout=self.timeout)
        self.assertGreater(len(js_msg.position), 10, "Robot model doesn't have enough joints (expected humanoid)")
    
    def test_communication_links(self):
        """Test that all necessary ROS topics are available"""
        topics_needed = [
            '/capstone_humanoid/joint_states',
            '/capstone_humanoid/pose',
            '/capstone_humanoid/cmd_vel',
            '/capstone_humanoid/health_status'
        ]
        
        available_topics = rospy.get_published_topics()
        available_topic_names = [topic[0] for topic in available_topics]
        
        for topic in topics_needed:
            self.assertIn(topic, available_topic_names, f"Required topic {topic} not available")
    
    def test_health_system(self):
        """Test that the robot health monitoring system is working"""
        timeout = time.time() + self.timeout
        while self.health_status is None:
            if time.time() > timeout:
                self.fail("Health monitoring system not responding")
            time.sleep(0.1)
        
        # Initially, robot should be healthy
        self.assertTrue(self.health_status, "Robot health status should be healthy initially")
    
    def tearDown(self):
        """Cleanup after tests"""
        self.joint_sub.unregister()
        self.pose_sub.unregister()
        self.health_sub.unregister()

if __name__ == '__main__':
    import rostest
    rostest.rosrun('capstone_project', 'environment_validator', EnvironmentValidator)
```

**Automated Setup Verification**:
```bash
#!/bin/bash
# capstone_project/scripts/validate_setup.sh

echo "Starting Capstone Simulation Environment Validation..."

# Check ROS 2 installation
if ! command -v ros2 &> /dev/null; then
    echo "ERROR: ROS 2 is not installed or not in PATH"
    exit 1
else
    echo "✓ ROS 2 installation verified"
fi

# Check Isaac Sim availability
if python3 -c "import omni; print('Isaac Sim available')" &> /dev/null; then
    echo "✓ Isaac Sim available"
else
    echo "WARNING: Isaac Sim not available - simulation will be limited"
fi

# Check Gazebo installation
if command -v gazebo &> /dev/null; then
    echo "✓ Gazebo installation verified"
else
    echo "ERROR: Gazebo is not installed"
    exit 1
fi

# Check Unity project setup
UNITY_PROJECT_PATH="$HOME/capstone_project/unity/capstone_visualization"
if [ -d "$UNITY_PROJECT_PATH" ]; then
    echo "✓ Unity project structure verified"
else
    echo "WARNING: Unity project not found at $UNITY_PROJECT_PATH"
fi

# Check required packages
REQUIRED_PACKAGES=(
    "robot_state_publisher"
    "joint_state_publisher"
    "controller_manager"
    "nav2_bringup"
)

for package in "${REQUIRED_PACKAGES[@]}"; do
    if ros2 pkg list | grep -q "$package"; then
        echo "✓ Required package $package available"
    else
        echo "ERROR: Required package $package not installed"
        exit 1
    fi
done

# Check for robot model
if [ -f "$HOME/capstone_project/capstone_robot_description/urdf/capstone_humanoid.urdf" ]; then
    echo "✓ Robot model file found"
else
    echo "ERROR: Robot model file not found"
    exit 1
fi

echo ""
echo "=== Validation Summary ==="
echo "✓ Basic system requirements met"
echo "✓ ROS 2 environment configured"
echo "✓ Simulation platforms checked"
echo "✓ Required packages available"
echo "✓ Robot model found"
echo ""
echo "Capstone simulation environment setup validation PASSED!"
echo "You may now proceed with the capstone project implementation."
```

## Troubleshooting Common Issues

### Installation Troubleshooting

Solutions for common installation issues:

**Isaac Sim Issues**:
```bash
# If Isaac Sim fails to launch
nvidia-smi  # Check GPU drivers
glxinfo | grep "OpenGL renderer"  # Check OpenGL support
# For headless systems, ensure virtual display is set up
export DISPLAY=:0
```

**ROS 2 Connection Issues**:
```bash
# Check ROS 2 network configuration
echo $ROS_DOMAIN_ID
echo $ROS_LOCALHOST_ONLY
# For multi-platform communication
export ROS_DOMAIN_ID=0
export ROS_LOCALHOST_ONLY=0
```

**Unity-ROS Connection Issues**:
```bash
# Test ROS-TCP-Connector
telnet localhost 10000
# Check firewall settings
sudo ufw allow 10000
```

## Performance Optimization

### Simulation Performance Tuning

Optimizing the simulation environment for better performance:

**Physics Performance**:
- Use simplified collision geometries for fast simulation
- Adjust solver iterations based on required accuracy
- Implement level-of-detail (LOD) for complex objects
- Use fixed time steps for consistent performance

**Rendering Performance**:
- Adjust rendering quality settings based on hardware
- Implement occlusion culling for large environments
- Use LOD systems for detailed models
- Optimize texture and mesh loading

**Resource Management**:
- Monitor and limit resource usage during simulation
- Implement efficient memory management for large datasets
- Use multithreading where appropriate
- Cache frequently accessed data

## Exercises and Self-Check

1. **Environment Setup**: Set up the complete simulation environment on your system. Validate that Isaac Sim, Gazebo, and Unity components are properly installed and communicating.

2. **Robot Model Validation**: Import a humanoid robot model into both Isaac Sim and Gazebo. Verify that joint configurations and physical properties match between platforms.

3. **Communication Testing**: Set up ROS 2 communication between all simulation components. Verify that messages are properly exchanged between platforms.

4. **Performance Benchmarking**: Measure and optimize simulation performance. Document the frame rates and resource usage with different numbers of robots and complexity levels.

5. **Error Recovery**: Test how the simulation environment handles component failures. Implement appropriate error handling and recovery mechanisms.

## Summary

The capstone simulation environment setup represents a critical foundation for the entire project. By properly configuring Isaac Sim, Gazebo, and Unity with appropriate networking and communication infrastructure, students establish a comprehensive digital twin environment capable of supporting all aspects of humanoid robot development.

The environment must balance realism with computational efficiency, providing a platform that supports complex algorithm development while remaining responsive and stable for extended testing sessions. The multi-platform integration leverages the strengths of each simulation environment while creating a unified development and testing platform.

Success in this setup phase is essential for the remainder of the capstone project. Students should ensure thorough validation of all components and establish clear procedures for troubleshooting any issues that may arise during the development process.

The next chapter will explore the implementation of the perception pipeline, building upon this simulation foundation to enable the robot to understand and interact with its environment.

---

**Keywords**: Simulation Environment, Isaac Sim, Gazebo, Unity, ROS 2, Humanoid Robot, Digital Twin, Environment Setup